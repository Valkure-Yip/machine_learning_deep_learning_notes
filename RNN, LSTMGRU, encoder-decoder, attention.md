# RNN, LSTM/GRU, encoder-decoder, attention

## RNN

- ğŸ‘‰ RNNåŸºæœ¬åŸç† [ä¸€æ–‡ææ‡‚RNNï¼ˆå¾ªç¯ç¥ç»ç½‘ç»œï¼‰åŸºç¡€ç¯‡ - çŸ¥ä¹](https://zhuanlan.zhihu.com/p/30844905)

- [[ä¸€æ–‡çœ‹æ‡‚å¾ªç¯ç¥ç»ç½‘ç»œ RNNï¼ˆ2ç§ä¼˜åŒ–ç®—æ³•+5ä¸ªå®é™…åº”ç”¨ï¼‰](https://easyai.tech/ai-definition/rnn/)](https://zhuanlan.zhihu.com/p/30844905)

  åŠ¨ç”» [Illustrated Guide to Recurrent Neural Networks | by Michael Phi | Towards Data Science](https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9)

## LSTM & GRU

- ğŸ‘‰ åŠ¨ç”» [Illustrated Guide to LSTMâ€™s and GRUâ€™s: A step by step explanation | by Michael Phi | Towards Data Science](https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21)

## encoder-decoder

- ğŸ‘‰ Encoder-decoder detailed explain & attention: [A Guide to the Encoder-Decoder Model and the Attention Mechanism | by Eduardo MuÃ±oz | Better Programming](https://betterprogramming.pub/a-guide-on-the-encoder-decoder-model-and-the-attention-mechanism-401c836e2cdb)

- with pytorch codeï¼š[10.6. The Encoderâ€“Decoder Architecture â€” Dive into Deep Learning 1.0.3 documentation](https://d2l.ai/chapter_recurrent-modern/encoder-decoder.html) 
  and [10.7. Sequence-to-Sequence Learning for Machine Translation â€” Dive into Deep Learning 1.0.3 documentation](https://d2l.ai/chapter_recurrent-modern/seq2seq.html)

- Video explain: [Encoder-decoder architecture: Overview - YouTube](https://www.youtube.com/watch?v=zbdong_h-x4&ab_channel=GoogleCloudTech)

- Hugging Face model: https://huggingface.co/docs/transformers/model_doc/encoder-decoder

## self-attention & transformer

- ğŸ‘‰ Detailed explain of self-attention & transformer with pytorch codes [Transformers from scratch | peterbloem.nl](https://peterbloem.nl/blog/transformers)
- Positional encoding: [A Gentle Introduction to Positional Encoding in Transformer Models, Part 1 - MachineLearningMastery.com](https://machinelearningmastery.com/a-gentle-introduction-to-positional-encoding-in-transformer-models-part-1/)
- A pytorch official example with code: [Language Modeling with nn.Transformer and torchtext â€” PyTorch Tutorials 2.0.1+cu117 documentation](https://pytorch.org/tutorials/beginner/transformer_tutorial.html#load-and-batch-data)
